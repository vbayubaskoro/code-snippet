{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at high-frequency words in top performers' resumes vs in bottom performers\n",
    "# look at topics/words by PLSA in top and bottom bins and see overlaps \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling Analysis  \n",
    "Looking at overlapping topics/words in the top and bottom employee bins. We want to suggest words to our client that are only in the top bin. Suggestions for key words to look for in applicants resume. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "426"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a pandas data frame \n",
    "data = pd.read_csv(\"resume_words.tsv\",sep=\"\\t\")\n",
    "type(data)\n",
    "data.columns\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emp_id</th>\n",
       "      <th>durationSinceFirstEngagement</th>\n",
       "      <th>performance_indicator</th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaliyah</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aas</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abc</th>\n",
       "      <th>...</th>\n",
       "      <th>yrs</th>\n",
       "      <th>zachary</th>\n",
       "      <th>zeta</th>\n",
       "      <th>zion</th>\n",
       "      <th>zip</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoological</th>\n",
       "      <th>zumba</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>C320K60000K0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>CLS2PN001040</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CLMXHR000040</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>CNF9JR000040</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>CLL1KT000040</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 8469 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   emp_id           durationSinceFirstEngagement  performance_indicator   aa  \\\n",
       "0  C320K60000K0                            315.0                  0.500  0.0   \n",
       "1  CLS2PN001040                             80.0                  0.375  0.0   \n",
       "2  CLMXHR000040                             86.0                  0.375  0.0   \n",
       "3  CNF9JR000040                             49.0                  0.375  0.0   \n",
       "4  CLL1KT000040                             83.0                  0.375  0.0   \n",
       "\n",
       "   aaa  aaliyah  aaron  aas  abandoned  abc  ...  yrs  zachary  zeta  zion  \\\n",
       "0  0.0      0.0    0.0  0.0        0.0  0.0  ...  0.0      0.0   0.0   0.0   \n",
       "1  0.0      0.0    0.0  0.0        0.0  0.0  ...  0.0      0.0   0.0   0.0   \n",
       "2  0.0      0.0    0.0  0.0        0.0  0.0  ...  0.0      0.0   0.0   0.0   \n",
       "3  0.0      0.0    0.0  0.0        0.0  0.0  ...  0.0      0.0   0.0   0.0   \n",
       "4  0.0      0.0    0.0  0.0        0.0  0.0  ...  0.0      0.0   0.0   0.0   \n",
       "\n",
       "   zip  zone  zoo  zoological  zumba  zurich  \n",
       "0  0.0   0.0  0.0         0.0    0.0     0.0  \n",
       "1  0.0   0.0  0.0         0.0    0.0     0.0  \n",
       "2  0.0   0.0  0.0         0.0    0.0     0.0  \n",
       "3  0.0   0.0  0.0         0.0    0.0     0.0  \n",
       "4  0.0   0.0  0.0         0.0    0.0     0.0  \n",
       "\n",
       "[5 rows x 8469 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What the data looks like \n",
    "data.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vanessabayubaskoro/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/vanessabayubaskoro/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer  \n",
    "import nltk  \n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tenure and Performance - numbers are from Jim\n",
    "# Top Category (above these scores) \n",
    "good_per = 0.37\n",
    "good_dur = 226\n",
    "# Bottom Category (below these scores)\n",
    "bad_per = 0.27\n",
    "bad_dur = 84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top employees indeces based on tenure: \n",
      "[0, 5, 8, 10, 15, 17, 44, 56, 71, 72, 73, 74, 75, 76, 77, 79, 80, 82, 83, 87, 89, 95, 101, 104, 112, 114, 121, 122, 127, 133, 138, 140, 145, 149, 163, 169, 172, 186, 187, 189, 190, 191, 193, 195, 197, 201, 202, 203, 208, 209, 210, 214, 216, 218, 220, 222, 223, 226, 229, 230, 231, 232, 233, 234, 236, 239, 240, 241, 242, 243, 246, 247, 249, 257, 260, 263, 269, 273, 277, 280, 283, 284, 287, 288, 289, 290, 292, 294, 296, 298, 299, 301, 302, 303, 305, 306, 316, 318, 322, 323, 324, 325, 326, 329, 330, 332, 334, 337, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 356, 357, 358, 363, 365, 366, 368, 369, 373, 381, 385, 387, 392, 393, 394, 396, 397, 398, 403, 405, 407, 411, 412, 413, 417, 419, 421]\n",
      "Number of top employees based on tenure: \n",
      "148\n",
      "Bottom employees indeces based on tenure: \n",
      "[1, 3, 4, 11, 14, 16, 18, 22, 25, 26, 27, 28, 29, 31, 33, 45, 46, 48, 52, 53, 55, 58, 60, 63, 64, 67, 69, 70, 78, 86, 91, 92, 96, 97, 106, 111, 113, 115, 117, 118, 123, 124, 125, 134, 135, 137, 139, 141, 143, 144, 151, 153, 154, 156, 157, 160, 165, 166, 167, 168, 171, 174, 175, 177, 179, 183, 184, 185, 188, 194, 196, 199, 200, 206, 207, 211, 212, 215, 221, 224, 227, 235, 237, 245, 252, 254, 255, 258, 259, 262, 264, 265, 266, 268, 270, 275, 278, 281, 293, 295, 297, 309, 311, 313, 315, 317, 327, 328, 331, 333, 335, 336, 353, 355, 360, 361, 370, 371, 372, 376, 383, 389, 395, 399, 400, 401, 402, 404, 406, 408, 409, 415, 416, 418, 420, 422, 423, 424, 425]\n",
      "Number of bottom employees based on tenure: \n",
      "139\n"
     ]
    }
   ],
   "source": [
    "# Grab Top Category employees index, tenure-based \n",
    "\n",
    "index_ls = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    if ( data.iloc[[i]]['durationSinceFirstEngagement'] > good_dur).bool():\n",
    "        index_ls.append(i)\n",
    "        \n",
    "print(\"Top employees indeces based on tenure: \" )\n",
    "print(index_ls)\n",
    "print(\"Number of top employees based on tenure: \")\n",
    "print(len(index_ls))\n",
    "        \n",
    "# Grab Bottom Categorry employees index, tenure-based\n",
    "bottom_index = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    if ( data.iloc[[i]]['durationSinceFirstEngagement'] < bad_dur).bool():\n",
    "        bottom_index.append(i)\n",
    "        \n",
    "print(\"Bottom employees indeces based on tenure: \")\n",
    "print(bottom_index)\n",
    "print(\"Number of bottom employees based on tenure: \")\n",
    "print(len(bottom_index))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile all words from a resume as one string for all employees in a category \n",
    "X = []\n",
    "for i, (index,row) in enumerate(data.iterrows()):\n",
    "    if i in index_ls: \n",
    "        docwords = data.iloc[i,3:]\n",
    "        X.append( ' '.join(list(docwords[docwords==1].index.values) ) )\n",
    "        \n",
    "        \n",
    "len(X) \n",
    "\n",
    "\n",
    "X2 = []\n",
    "for i, (index,row) in enumerate(data.iterrows()):\n",
    "    if i in bottom_index: \n",
    "        docwords = data.iloc[i,3:]\n",
    "        X2.append( ' '.join(list(docwords[docwords==1].index.values) ) )\n",
    "len(X2)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "stemmer = WordNetLemmatizer()\n",
    "documents = []\n",
    "\n",
    "\n",
    "\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "for sen in range(0, len(X)):  \n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', str(X[sen]))\n",
    "\n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "\n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "\n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "\n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "\n",
    "    ##Remove word numbers\n",
    "    #document = re.sub(\" \\d+\", \" \", document)\n",
    "    \n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "\n",
    "    # Lemmatization\n",
    "    document = document.split()\n",
    "\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "    \n",
    "   # list_of_locations = [\"chicago\",\"minnesota\",\"minneapolis\", \" dc \", \" il \", \" mn \", \" wa \", \"washington\", \"illinois\", \"maryland\", \" md \"]\n",
    "\n",
    "    #for city in list_of_locations:\n",
    "     #   document = document.replace(city, \" \")\n",
    "\n",
    "\n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf-idf features for NMF...\n"
     ]
    }
   ],
   "source": [
    "# Use tf-idf features for NMF.\n",
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_top_words = 20\n",
    "n_components = 6\n",
    "\n",
    "print(\"Extracting tf-idf features for NMF...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, \n",
    "                                   min_df=2,\n",
    "                                   max_features=n_features,\n",
    "                                   stop_words='english')\n",
    "\n",
    "tfidf = tfidf_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Tenure Category PLSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the NMF model (generalized Kullback-Leibler divergence) with tf-idf features, n_samples=2000 and n_features=1000...\n",
      "\n",
      "Topics in NMF model (generalized Kullback-Leibler divergence):\n",
      "Topic #0: staff ability professional diploma objective services assistant summary set goals new calls communication according references safety knowledge management including excellent\n",
      "Topic #1: english gpa communication degree year spanish community college social volunteer word society computer club events awards professional microsoft diploma bilingual\n",
      "Topic #2: september associate october july responsible sales march additional employer april certifications ambassador authorized yahoo person college modern certified information state\n",
      "Topic #3: diploma clean environment cleaning stocked area dining foods prep tasks duties community aid properly drinks new children use maintained preparing\n",
      "Topic #4: college cashier restaurant organized ave diploma environment able self inventory fast quality motivated exceptional making reliable order working flexible hard\n",
      "Topic #5: assistant yahoo company manager position associate line cash cook excel office ave microsoft grill open crew register great shift powerpoint\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model (generalized Kullback-Leibler divergence) with \"\n",
    "      \"tf-idf features, n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "\n",
    "nmf = NMF(n_components=n_components, random_state=1,\n",
    "          beta_loss='kullback-leibler', solver='mu', max_iter=1000, alpha=.1,\n",
    "          l1_ratio=.5).fit(tfidf)\n",
    "\n",
    "\n",
    "print(\"\\nTopics in NMF model (generalized Kullback-Leibler divergence):\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bottom Tenure Category PLSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: excel counting outreach offers va tickets language balanced correct desk establishment mcdonalds networking purchase classroom association coach updated honor associates\n",
      "Topic #1: bathrooms leader consistently coordinator believe culinary workers online assisting correct guest presentations enthusiasm offers yahoo drink met level clean floor\n",
      "Topic #2: multitask worked extensive administration prepping main court opportunity stay served grill mentor pulling monitoring fast condition stations profile company calm\n",
      "Topic #3: store qualifications tickets drink flexible executed fall station mail consistently best dedicated paced having member pulling routine listening marlboro basset\n",
      "Topic #4: opening receive registers benefits clean look drink reported entering hard complaints culinary trash awards locate changes completed associate association concerns\n",
      "Topic #5: point cook awards oversaw consistently applied works years offers ability proficient establishment chicken graduated systems delivered rules coordinator meetings supported\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf2 = tfidf_vectorizer.fit_transform(X2)\n",
    "nmf2 = NMF(n_components=n_components, random_state=1,\n",
    "          beta_loss='kullback-leibler', solver='mu', max_iter=1000, alpha=.1,\n",
    "          l1_ratio=.5).fit(tfidf2)\n",
    "print_top_words(nmf2, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
